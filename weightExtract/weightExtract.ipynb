{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "from torch.utils.data import DataLoader\n",
    "from thop import profile\n",
    "from ptflops import get_model_complexity_info\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from utils.datasets import *\n",
    "from utils.utils import *\n",
    "from quant_dorefa import *\n",
    "\n",
    "from mymodel import *\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('weights/4w4a/test_best.pt', map_location=torch.device('cpu'))\n",
    "# model = UltraNet()\n",
    "# model.load_state_dict(checkpoint[])\n",
    "# model.hyp = hyp\n",
    "# model.nc = 1\n",
    "# model.arc = 'default'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.parameters())\n",
    "# print(model['model'])\n",
    "# for layers in model:\n",
    "#     print(layers)\n",
    "# summary(model, (3, 320, 160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model['model']:\n",
    "#     print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "#     if(len(model['model'][param_tensor].size()) > 1):\n",
    "    print(param_tensor, model['model'][param_tensor].size())\n",
    "\n",
    "# print(model['model']['layers.0.weight'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_0_weight = model['model']['layers.0.weight']\n",
    "conv_1_weight = model['model']['layers.4.weight']\n",
    "conv_2_weight = model['model']['layers.8.weight']\n",
    "conv_3_weight = model['model']['layers.12.weight']\n",
    "conv_4_weight = model['model']['layers.16.weight']\n",
    "conv_5_weight = model['model']['layers.19.weight']\n",
    "conv_6_weight = model['model']['layers.22.weight']\n",
    "conv_7_weight = model['model']['layers.25.weight']\n",
    "conv_8_weight = model['model']['layers.28.weight']\n",
    "print(conv_0_weight)\n",
    "# torch.save(conv_0_weight, 'conv_0_original.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max and Min value in bn_1_weight: tensor(0.74779) tensor(0.24101)\n",
      "Max and Min value in bn_5_weight: tensor(0.61837) tensor(0.19282)\n",
      "Max and Min value in bn_9_weight: tensor(0.71140) tensor(0.16660)\n",
      "Max and Min value in bn_13_weight: tensor(0.48525) tensor(0.19018)\n",
      "Max and Min value in bn_17_weight: tensor(1.01425) tensor(0.19093)\n",
      "Max and Min value in bn_20_weight: tensor(0.66609) tensor(0.20678)\n",
      "Max and Min value in bn_23_weight: tensor(1.26842) tensor(0.22393)\n",
      "Max and Min value in bn_26_weight: tensor(1.41240) tensor(0.13694)\n",
      "Max and Min value in bn_1_bias: tensor(4.11842) tensor(-3.47873)\n"
     ]
    }
   ],
   "source": [
    "bn_1_weight = model['model']['layers.1.weight']\n",
    "bn_5_weight = model['model']['layers.5.weight']\n",
    "bn_9_weight = model['model']['layers.9.weight']\n",
    "bn_13_weight = model['model']['layers.13.weight']\n",
    "bn_17_weight = model['model']['layers.17.weight']\n",
    "bn_20_weight = model['model']['layers.20.weight']\n",
    "bn_23_weight = model['model']['layers.23.weight']\n",
    "bn_26_weight = model['model']['layers.26.weight']\n",
    "\n",
    "bn_1_bias = model['model']['layers.1.bias']\n",
    "bn_5_bias = model['model']['layers.5.bias']                           \n",
    "bn_9_bias = model['model']['layers.9.bias']                          \n",
    "bn_13_bias = model['model']['layers.13.bias']                                       \n",
    "bn_17_bias = model['model']['layers.17.bias']                          \n",
    "bn_20_bias = model['model']['layers.20.bias']                          \n",
    "bn_23_bias = model['model']['layers.23.bias']                          \n",
    "bn_26_bias = model['model']['layers.26.bias']     \n",
    "# print(bn_1_weight)\n",
    "print(\"Max and Min value in bn_1_weight:\", bn_1_weight.max(), bn_1_weight.min())\n",
    "print(\"Max and Min value in bn_5_weight:\", bn_5_weight.max(), bn_5_weight.min())\n",
    "print(\"Max and Min value in bn_9_weight:\", bn_9_weight.max(), bn_9_weight.min())\n",
    "print(\"Max and Min value in bn_13_weight:\", bn_13_weight.max(), bn_13_weight.min())\n",
    "print(\"Max and Min value in bn_17_weight:\", bn_17_weight.max(), bn_17_weight.min())\n",
    "print(\"Max and Min value in bn_20_weight:\", bn_20_weight.max(), bn_20_weight.min())\n",
    "print(\"Max and Min value in bn_23_weight:\", bn_23_weight.max(), bn_23_weight.min())\n",
    "print(\"Max and Min value in bn_26_weight:\", bn_26_weight.max(), bn_26_weight.min())\n",
    "print(\"Max and Min value in bn_1_bias:\", bn_1_bias.max(), bn_1_bias.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w_quant(in_f, k):\n",
    "    in_f = torch.tanh(in_f)\n",
    "    n = float(2 ** (k-1)  - 1)\n",
    "    in_f = in_f / torch.max(torch.abs(in_f))\n",
    "    out = torch.round(in_f * n) / n\n",
    "    return out\n",
    "\n",
    "def get_w_int(in_f, k):\n",
    "    in_f = torch.tanh(in_f)\n",
    "    n = float(2 ** (k-1)  - 1)\n",
    "    in_f = in_f / torch.max(torch.abs(in_f))\n",
    "    out = torch.round(in_f * n)\n",
    "    return out\n",
    "\n",
    "def get_wbnI(in_f, K_bit, W_bit, Si, So):\n",
    "    wbnI = (2**W_bit/(2**W_bit-1))*Si*in_f*2**K_bit/So\n",
    "    return wbnI\n",
    "\n",
    "def get_wbn_int(in_f, K_bit, W_bit, Si, So):\n",
    "    wbnI = (2**W_bit/(2**W_bit-1))*Si*in_f*2**K_bit/So\n",
    "    wbn_int = torch.round(wbnI)\n",
    "    return wbn_int\n",
    "\n",
    "def power_log(x):\n",
    "    return 2**(math.ceil(math.log(x, 2)))\n",
    "\n",
    "def get_bbnI(in_f, K_bit, W_bit, Si, So):\n",
    "    bbnI = (in_f*2**(W_bit-1+K_bit)/So)*2**K_bit\n",
    "    return bbnI\n",
    "\n",
    "def get_bbn_int(in_f, K_bit, W_bit, Si, So):\n",
    "    bbnI = (in_f*2**(W_bit-1+K_bit)/So)*2**K_bit\n",
    "    bbn_int = torch.round(bbnI)\n",
    "    return bbn_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_0_I = get_wbnI(bn_1_weight, 12, 4, 1, 1)\n",
    "bn_1_I = get_wbnI(bn_5_weight, 12, 4, 1, 1)\n",
    "bn_2_I = get_wbnI(bn_9_weight, 12, 4, 1, 1)\n",
    "bn_3_I = get_wbnI(bn_13_weight, 12, 4, 1, 1)\n",
    "bn_4_I = get_wbnI(bn_17_weight, 12, 4, 1, 1)\n",
    "bn_5_I = get_wbnI(bn_20_weight, 12, 4, 1, 1)\n",
    "bn_6_I = get_wbnI(bn_23_weight, 12, 4, 1, 1)\n",
    "bn_7_I = get_wbnI(bn_26_weight, 12, 4, 1, 1)\n",
    "print(\"bn_1_weight range:\", bn_0_I.max().item(), bn_0_I.min().item(), \"Required bitwidth: \", math.log(power_log(bn_0_I.max().data), 2))\n",
    "print(\"bn_5_weight range:\", bn_1_I.max().item(), bn_1_I.min().item(), \"Required bitwidth: \", math.log(power_log(bn_1_I.max().data), 2))\n",
    "print(\"bn_9_weight range:\", bn_2_I.max().item(), bn_2_I.min().item(), \"Required bitwidth: \", math.log(power_log(bn_2_I.max().data), 2))\n",
    "print(\"bn_13_weight range:\", bn_3_I.max().item(), bn_3_I.min().item(), \"Required bitwidth: \", math.log(power_log(bn_3_I.max().data), 2))\n",
    "print(\"bn_17_weight range:\", bn_4_I.max().item(), bn_4_I.min().item(), \"Required bitwidth: \", math.log(power_log(bn_4_I.max().data), 2))\n",
    "print(\"bn_20_weight range:\", bn_5_I.max().item(), bn_5_I.min().item(), \"Required bitwidth: \", math.log(power_log(bn_5_I.max().data), 2))\n",
    "print(\"bn_23_weight range:\", bn_6_I.max().item(), bn_6_I.min().item(), \"Required bitwidth: \", math.log(power_log(bn_6_I.max().data), 2))\n",
    "print(\"bn_26_weight range:\", bn_7_I.max().item(), bn_7_I.min().item(), \"Required bitwidth: \", math.log(power_log(bn_7_I.max().data), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn_0_b_int max power of 2:  21\n",
      "bn_1_b_int max power of 2:  17\n",
      "bn_2_b_int max power of 2:  20\n",
      "bn_3_b_int max power of 2:  17\n",
      "bn_4_b_int max power of 2:  18\n",
      "bn_5_b_int max power of 2:  17\n",
      "bn_6_b_int max power of 2:  18\n",
      "bn_7_b_int max power of 2:  20\n"
     ]
    }
   ],
   "source": [
    "bn_0_w_int = get_wbn_int(bn_1_weight, 12, 4, 1, 1)\n",
    "bn_1_w_int = get_wbn_int(bn_5_weight, 12, 4, 1, 1)\n",
    "bn_2_w_int = get_wbn_int(bn_9_weight, 12, 4, 1, 1)\n",
    "bn_3_w_int = get_wbn_int(bn_13_weight, 12, 4, 1, 1)\n",
    "bn_4_w_int = get_wbn_int(bn_17_weight, 12, 4, 1, 1)\n",
    "bn_5_w_int = get_wbn_int(bn_20_weight, 12, 4, 1, 1)\n",
    "bn_6_w_int = get_wbn_int(bn_23_weight, 12, 4, 1, 1)\n",
    "bn_7_w_int = get_wbn_int(bn_26_weight, 12, 4, 1, 1)\n",
    "print(\"bn_0_w_int max power of 2:\", bn_0_w_int.max().item(), bn_0_w_int.min().item(), \"Required bitwidth: \", math.log(power_log(bn_0_w_int.max().item()), 2))\n",
    "print(\"bn_1_w_int max power of 2:\", bn_1_w_int.max().item(), bn_1_w_int.min().item(), \"Required bitwidth: \", math.log(power_log(bn_1_w_int.max().data), 2))\n",
    "print(\"bn_2_w_int max power of 2:\", bn_2_w_int.max().item(), bn_2_w_int.min().item(), \"Required bitwidth: \", math.log(power_log(bn_2_w_int.max().data), 2))\n",
    "print(\"bn_3_w_int max power of 2:\", bn_3_w_int.max().item(), bn_3_w_int.min().item(), \"Required bitwidth: \", math.log(power_log(bn_3_w_int.max().data), 2))\n",
    "print(\"bn_4_w_int max power of 2:\", bn_4_w_int.max().item(), bn_4_w_int.min().item(), \"Required bitwidth: \", math.log(power_log(bn_4_w_int.max().item), 2))\n",
    "print(\"bn_5_w_int max power of 2:\", bn_5_w_int.max().item(), bn_5_w_int.min().item(), \"Required bitwidth: \", math.log(power_log(bn_5_w_int.max().item()), 2))\n",
    "print(\"bn_6_w_int max power of 2:\", bn_6_w_int.max().item(), bn_6_w_int.min().item(), \"Required bitwidth: \", math.log(power_log(bn_6_w_int.max().item()), 2))\n",
    "print(\"bn_7_w_int max power of 2:\", bn_7_w_int.max().item(), bn_7_w_int.min().item(), \"Required bitwidth: \", math.log(power_log(bn_7_w_int.max().item()), 2))\n",
    "bn_0_b_I = get_bbnI(bn_1_bias, 12, 4, 1, 1)\n",
    "bn_0_b_int = get_bbn_int(bn_1_bias, 12, 4, 1, 1)\n",
    "bn_1_b_int = get_bbn_int(bn_5_bias, 12, 4, 1, 1)\n",
    "bn_2_b_int = get_bbn_int(bn_9_bias, 12, 4, 1, 1)\n",
    "bn_3_b_int = get_bbn_int(bn_13_bias, 12, 4, 1, 1)\n",
    "bn_4_b_int = get_bbn_int(bn_17_bias, 12, 4, 1, 1)\n",
    "bn_5_b_int = get_bbn_int(bn_20_bias, 12, 4, 1, 1)\n",
    "bn_6_b_int = get_bbn_int(bn_23_bias, 12, 4, 1, 1)\n",
    "bn_7_b_int = get_bbn_int(bn_26_bias, 12, 4, 1, 1)\n",
    "# print(\"bn_0_b_I: \", round(math.log(power_log(bn_0_b_I.max().item()))))\n",
    "print(\"bn_0_b_int max power of 2: \", round(math.log(power_log(bn_0_b_int.max().item()))))\n",
    "print(\"bn_1_b_int max power of 2: \", round(math.log(power_log(bn_1_b_int.max().item()))))\n",
    "print(\"bn_2_b_int max power of 2: \", round(math.log(power_log(bn_2_b_int.max().item()))))\n",
    "print(\"bn_3_b_int max power of 2: \", round(math.log(power_log(bn_3_b_int.max().item()))))\n",
    "print(\"bn_4_b_int max power of 2: \", round(math.log(power_log(bn_4_b_int.max().item()))))\n",
    "print(\"bn_5_b_int max power of 2: \", round(math.log(power_log(bn_5_b_int.max().item()))))\n",
    "print(\"bn_6_b_int max power of 2: \", round(math.log(power_log(bn_6_b_int.max().item()))))\n",
    "print(\"bn_7_b_int max power of 2: \", round(math.log(power_log(bn_7_b_int.max().item()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bn_1_weight_int = get_w_int(bn_1_weight, 14)\n",
    "# bn_5_weight_int = get_w_int(bn_1_weight, 13)\n",
    "# bn_9_weight_int = get_w_int(bn_1_weight, 12)\n",
    "# bn_13_weight_int = get_w_int(bn_1_weight, 11)\n",
    "# bn_17_weight_int = get_w_int(bn_1_weight, 13)\n",
    "# bn_20_weight_int = get_w_int(bn_1_weight, 12)\n",
    "# bn_23_weight_int = get_w_int(bn_1_weight, 13)\n",
    "# bn_26_weight_int = get_w_int(bn_1_weight, 14)\n",
    "\n",
    "# bn_1_bias_int = get_w_int(bn_1_bias,26)\n",
    "# bn_5_bias_int = get_w_int(bn_1_bias,21)\n",
    "# bn_9_bias_int = get_w_int(bn_1_bias,22)\n",
    "# bn_13_bias_int = get_w_int(bn_1_bias,21)\n",
    "# bn_17_bias_int = get_w_int(bn_1_bias,21)\n",
    "# bn_20_bias_int = get_w_int(bn_1_bias,21)\n",
    "# bn_23_bias_int = get_w_int(bn_1_bias,22)\n",
    "# bn_26_bias_int = get_w_int(bn_1_bias,23)\n",
    "\n",
    "np.save('bn_0_weight', bn_0_w_int)\n",
    "np.save('bn_0_bias', bn_0_b_int)\n",
    "np.save('bn_1_weight', bn_1_w_int)\n",
    "np.save('bn_1_bias', bn_1_b_int)\n",
    "np.save('bn_2_weight', bn_2_w_int)\n",
    "np.save('bn_2_bias', bn_2_b_int)\n",
    "np.save('bn_3_weight', bn_3_w_int)\n",
    "np.save('bn_3_bias', bn_3_b_int)\n",
    "np.save('bn_4_weight', bn_4_w_int)\n",
    "np.save('bn_4_bias', bn_4_b_int)\n",
    "np.save('bn_5_weight', bn_5_w_int)\n",
    "np.save('bn_5_bias', bn_5_b_int)\n",
    "np.save('bn_6_weight', bn_6_w_int)\n",
    "np.save('bn_6_bias', bn_6_b_int)\n",
    "np.save('bn_7_weight', bn_7_w_int)\n",
    "np.save('bn_7_bias', bn_7_b_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_3_b = np.load('bn_3_weight.npy')\n",
    "print(bn_3_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_hex_line(in_f, size_value, SIMD, PE):\n",
    "    print(size_value)\n",
    "    print('{', end='')\n",
    "    for i in range(0, size_value[0]):  # OUT_channel traverse\n",
    "        if i%(size_value[0]/PE) == 0:\n",
    "            print('')\n",
    "            print('{', end = '')\n",
    "        for k1 in range(0, size_value[2]): # kernel trverse\n",
    "            for k2 in range(0, size_value[3]): # kernel traverse\n",
    "                for j in range(0, size_value[1]): # In_channel traverse\n",
    "                    if in_f[i][j][k1][k2] < 0:\n",
    "                        in_f[i][j][k1][k2] = in_f[i][j][k1][k2] * (-1) + 8\n",
    "                    if j/(size_value[1]/SIMD) == 0:\n",
    "                        print('\"0x', end='')\n",
    "                    formatted_data = format(int(in_f[i][j][k1][k2].item()), \"x\")\n",
    "#                     print(formatted_data, end = '')\n",
    "                    print(i, end='')\n",
    "                    if size_value[1] <= SIMD:\n",
    "                        if i == size_value[0]/PE -1:\n",
    "                            print('\"}', end='')\n",
    "                        else:\n",
    "                            if j == size_value[1]-1:\n",
    "                                print('\",', end='')\n",
    "#                             else:\n",
    "                    else:\n",
    "                        if int((j+1)%(size_value[1]/SIMD)) == 0:\n",
    "                            print('\",', end='')\n",
    "    print('}', end = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_reorg_2d(in_f, size_value, SIMD, PE):\n",
    "    print(size_value)\n",
    "    K = size_value[2]\n",
    "    IN_CH = size_value[1]\n",
    "    OUT_CH = size_value[0]\n",
    "#     weight_store[OUT_CH][OUT_CH*IN_CH*K*K]\n",
    "    rows, cols = (OUT_CH, IN_CH*K*K)\n",
    "    weight_store = [[0 for i in range(cols)] for j in range(rows)]\n",
    "#     dim_1 = PE\n",
    "#     dim_2 = K*K*OUT_CH/PE*IN_CH*SIMD\n",
    "    \n",
    "    for out_channel in range(0, OUT_CH):\n",
    "        for in_channel in range(0, IN_CH):\n",
    "            for ker1 in range(0, K):\n",
    "                for ker2 in range(0, K):\n",
    "                    weight_store[out_channel][in_channel*K*K + ker1*K + ker2] = int(in_f[out_channel][in_channel][ker1][ker2].item());\n",
    "    return weight_store, rows, cols\n",
    "\n",
    "def weight_print(weight_2d, rows, cols, SIMD, PE):\n",
    "    print('out_dim = ', int(PE), ',', int((cols/SIMD)*(rows/PE)))\n",
    "    print('{')\n",
    "    for i in range(0, rows):\n",
    "        if i%(rows/PE) == 0:\n",
    "            print('')\n",
    "            print('{')\n",
    "        simd_cnt = 0\n",
    "        for j in range(0, cols):\n",
    "            if weight_2d[i][j] < 0:\n",
    "                weight_2d[i][j] = weight_2d[i][j] * (-1) + 8\n",
    "            if j%SIMD == 0:\n",
    "                print('\"0x', end='')\n",
    "            formatted_data = format(int(weight_2d[i][j]), \"x\")\n",
    "            print(formatted_data, end='')\n",
    "            simd_cnt = simd_cnt + 1\n",
    "            if simd_cnt%SIMD == 0:\n",
    "                if j == cols-1 and (i+1)%(rows/PE)==0:\n",
    "                    if j == cols -1 and i == rows-1:\n",
    "                        print('\"}')\n",
    "                    else:\n",
    "                        print('\"},', end='')\n",
    "                else:\n",
    "                    print('\",', end='')\n",
    "    print('}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_0_wq = get_w_int(conv_0_weight, 4)\n",
    "np.save('conv_0',conv_0_wq)\n",
    "conv_1_wq = get_w_int(conv_1_weight, 4)\n",
    "np.save('conv_1',conv_1_wq)\n",
    "conv_2_wq = get_w_int(conv_2_weight, 4)\n",
    "np.save('conv_2',conv_2_wq)\n",
    "conv_3_wq = get_w_int(conv_3_weight, 4)\n",
    "np.save('conv_3',conv_3_wq)\n",
    "conv_4_wq = get_w_int(conv_4_weight, 4)\n",
    "np.save('conv_4',conv_4_wq)\n",
    "conv_5_wq = get_w_int(conv_5_weight, 4)\n",
    "np.save('conv_5',conv_5_wq)\n",
    "conv_6_wq = get_w_int(conv_6_weight, 4)\n",
    "np.save('conv_6',conv_6_wq)\n",
    "conv_7_wq = get_w_int(conv_7_weight, 4)\n",
    "np.save('conv_7',conv_7_wq)\n",
    "conv_8_wq = get_w_int(conv_8_weight, 4)\n",
    "np.save('conv_8',conv_8_wq)\n",
    "# print(conv_0_wq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('conv_8.npy')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_0_wq = get_w_int(conv_8_weight, 4)\n",
    "PE = 2\n",
    "SIMD = 8\n",
    "# print(conv_1_wq.data[0][0])\n",
    "size_value = conv_0_wq.size()\n",
    "# conv_0_wq = conv_0_wq.cpu()\n",
    "# conv_0_wq = get_w_int(conv_0_wq, 4)\n",
    "weight_store, rows, cols = weight_reorg_2d(conv_0_wq, size_value, 0, 0)\n",
    "print(rows, cols)\n",
    "weight_print(weight_store, rows, cols, SIMD, PE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conv_0_wq = get_w_int(conv_0_weight, 4)\n",
    "PE = 2\n",
    "SIMD = 8\n",
    "# print(conv_1_wq.data[0][0])\n",
    "size_value = conv_0_wq.size()\n",
    "conv_0_wq = conv_0_wq.cpu()\n",
    "print_hex_line(conv_0_wq.data, size_value, SIMD, PE)\n",
    "# print(size_value[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(size_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
